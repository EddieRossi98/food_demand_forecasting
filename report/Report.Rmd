---
title: "BEFD Project"
output: beamer_presentation
theme: "Berlin"
colortheme: "beaver"
fonttheme: "professionalfonts"
header-includes:
  - \setbeamercolor{structure}{fg=darkred}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
centers = read.csv("../data/fulfilment_center_info.csv")
meals = read.csv("../data/meal_info.csv")
sales = read.csv("../data/train.csv")
```

# Food Demand Forecasting

## **The business problem:**

A meal delivery company operates in multiple cities. They have various fulfillment centers in these cities for dispatching meal orders to their customers. We need to provide these centers the demand forecasting for upcoming weeks so that these centers will plan the stock of raw materials accordingly.

## **Task:**

Predict the demand for the next 10 weeks!

# Data sources

## Datasets

- Fulfilment center data
- Meal info data
- Sales historical data

# Fulfilment centers data features

## ***Variables:***

- **center_id**: Fulfilment identifier
- **city_code**: City id in which the center is located on
- **region_code**: Region id in which the center is located on
- **center_type**: Type of the center
- **op_area**: Size of the operational area

# Fulfilment centers data features summary

## ***Variables:***

- **center_id**: We have 
```{r, echo = F, results = 'asis'}
cat(length(unique(centers$center_id)))
```
different centers
- **city_code**: The company acts on
```{r, echo = F, results = 'asis'}
cat(length(unique(centers$city_code)))
```
different cities

# Fulfilment centers data features summary

**region_code**: These cities are located on
```{r, echo = F, results = 'asis'}
cat(length(unique(centers$region_code)))
```
different regions
```{r, echo = F, out.width="80%", fig.align='center'}
sums = rep(0,8)
names = levels(factor(centers$region_code))
for (i in 1:8) {
  sums[i] = sum(centers[, "region_code"] == names[i])
}
names = paste("Region", names)
heights = sums/nrow(centers)
b = barplot(names = names , height = heights, 
        col = c("darkred"),
        xlab = "Location",
        main = "Barplot",
        ylim = c(0,0.45))
text(b,heights,labels=sums, adj=c(0.5, -0.5))
```


# Fulfilment centers data features summary

**center_type**: There are
```{r, echo = F, results = 'asis'}
cat(length(unique(centers$center_type)))
```
centers types: A, B and C
```{r, echo = F, out.width="80%", fig.align='center'}
sums = c(0,0,0)
names = c("A", "B", "C")
for (i in 1:3) {
  sums[i] = sum(centers[, "center_type"] == paste("TYPE_", names[i], sep = ""))
}
heights = sums/nrow(centers)
b = barplot(names = names , height = heights, 
        col = c("darkred"),
        xlab = "Centers type",
        main = "Barplot",
        ylim = c(0,0.65))
text(b,heights,labels=sums, adj=c(0.5, -0.5))
```

# Fulfilment centers data features summary

- **op_area**:
```{r, echo = F, out.width="80%", fig.align='center'}
h = hist(centers$op_area, col = "darkred", border = "white",
     xlab = "Operational area size", main = "Histogram", 
     breaks = 7, probability = T)
text(h$mids,h$density,labels=h$counts, adj=c(0.5, -0.5))
```


# Fulfilment centers data rows

```{r, echo = F}
kable(head(centers), "pipe")
```

# Meal info

```{r, echo = F}
kable(head(meals), "pipe")
```

# Sales data

```{r, echo = F}
kable(head(sales[, c(1:5)]))
```

# Sales data

```{r, echo = F}
kable(head(sales[, c(1, 6,9)]))
```

# Correlations

```{r, echo = F}
X = merge(sales, centers, by = "center_id")
X = merge(X, meals,by = "meal_id")
corr = cor(X[, c(4,5,6,9,13)])
```
```{r, echo = F, out.width="80%", fig.align='center'}
library(ggplot2)
library(ggcorrplot)
ggcorrplot(corr, hc.order = TRUE, outline.col = "white", 
           colors = c("blue", "white", "darkred"), lab = TRUE) +
  ggtitle("Correlations between numerical variables")
```

# Modelling

Since we want to organize the goods for each specific fulflment center, we need to forecast the demand for each specific center. Moreover, we also need to stratify for each unique meal, since each of them requires a different set of raw materials. 
We propose a two-stage approach:

- First we account for the temporal relationship using the linear model, obtaining (hopefully) i.i.d. residuals
- Then we model the obtained residuals, using some flexible method such as the gradient boosting

# Linear model

We want to fit a straight line, between demand and time, for each combination of center and meal. This mean we should fit $N^ocenters \cdot N^omeals \ (77 \cdot 51 = 3927)$ linear models. But if we carefully craft some indicator variables we can specify all the simple linear models in to one single big linear model.

# Linear model

$$Y_{ij} = \beta_{0ij} + \beta_{1ij}week$$  $$\forall i=1,...,77; j=1,...,51$$
Is equivalent to:
$$ Y = \beta_{0} + \beta_{1}week + X_{ind} \beta_{level} +  X_{ind}\beta_{slope}\cdot week$$

# Linear model

where $X_{ind}$ is a vector with $51 \cdot77 - 1 = 3926$ columns, and is obtained as the interaction between the dummy expansion of the categorical variables center_id and meal_id. 

The model has $1 + 1 + 3926 + 3926 = 7854$ scalar parameters, that in the simple formulation there are 2 parameters for each model, so $2 \cdot77 \cdot 51 = 7854$






```{r eval=T, include=FALSE}
meal_feature = as.factor(X$meal_id)
center_feature =as.factor(X$center_id)
week = X$week
y = X$num_orders
ln_y = log(y)

val_idx = which(week > 130)


Design_matrix = Matrix::sparse.model.matrix( ~ week + meal_feature*center_feature + week*meal_feature*center_feature)
lin_model = glmnet::glmnet(Design_matrix, y, subset = -val_idx, 
                   alpha = 0.8, lambda = c(0, 0.01, 0.1, 1))
loglin_model = glmnet::glmnet(Design_matrix, ln_y, subset = -val_idx, 
                   alpha = 0.8, lambda = c(0, 0.01, 0.1, 1))

y_bar = mean(y[-val_idx])
dummy_val_rmse = sqrt(mean((y_bar - y[val_idx])^2))
dummy_val_mae = mean(abs(y_bar - y[val_idx]))

lin_val_rmse = rep(0, 4)
loglin_val_rmse = rep(0, 4)
lin_val_mae = rep(0, 4)
loglin_val_mae = rep(0, 4)
for(i in 1:4){
  predicted = glmnet::predict.glmnet(lin_model, newx = Design_matrix[val_idx,],s = lin_model$lambda[i])
  lin_val_rmse[i] = sqrt(mean((predicted - y[val_idx])^2))
  lin_val_mae[i] = mean(abs(predicted - y[val_idx]))
}
for(i in 1:4){
  predicted = exp(glmnet::predict.glmnet(loglin_model, newx = Design_matrix[val_idx,],s = lin_model$lambda[i]) )
  loglin_val_rmse[i] = sqrt(mean((predicted- y[val_idx])^2))
  loglin_val_mae[i] = mean(abs(predicted - y[val_idx]))
}
```

# Results

```{r, echo = F}
kable(data.frame(model = c("Mean", "LM", "LM on ln(y)"), 
                 RMSE = c(dummy_val_rmse, lin_val_rmse[1], loglin_val_rmse[1]),
                 MAE = c(dummy_val_mae, lin_val_mae[1], loglin_val_mae[1])
                 ))
```









